{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from config import *\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from import_data import Import_EfficientNetB7_data, Import_TripletNet_train_data\n",
    "from model.EfficientNetB7 import EfficientNetB7_model\n",
    "from model.TripletNet import TripletNet_model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_NAME == 'TripletNet':\n",
    "    train_triplet_generator = Import_TripletNet_train_data(TRAIN_DATA_PATH, BATCH_SIZE, IMAGE_SIZE)\n",
    "    val_triplet_generator = Import_TripletNet_train_data(VAL_DATA_PATH, BATCH_SIZE, IMAGE_SIZE)\n",
    "elif MODEL_NAME == 'EfficientNetB7':\n",
    "    train_generator, val_generator = Import_EfficientNetB7_data(IMAGE_SIZE, BATCH_SIZE, train_data_path=TRAIN_DATA_PATH, val_data_path=VAL_DATA_PATH).build_generators('train')\n",
    "\n",
    "callbacks = create_callbacks(CHECKPOINT_PATH, CHECKPOINT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start : 2024-06-06 04:40:05.863058+09:00\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb7 (Functional)  (None, 7, 7, 2560)       64097687  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2560)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2622464   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024)             4096      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,417,758\n",
      "Trainable params: 67,103,191\n",
      "Non-trainable params: 314,567\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.98800, saving model to C:/Users/USER/Desktop/Git/capstone/Capstone\\train_result\\EfficientNetB7_cropped_data_224_1000_0.0003_8\\checkpoint\\checkpoint-001-2.021863-1.987998-0.183032-0.181030.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 1.98800\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.98800\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.98800 to 1.80419, saving model to C:/Users/USER/Desktop/Git/capstone/Capstone\\train_result\\EfficientNetB7_cropped_data_224_1000_0.0003_8\\checkpoint\\checkpoint-004-1.786765-1.804189-0.282159-0.292157.h5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.80419\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.80419\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(RESULT_FILE_PATH):\n",
    "\tos.makedirs(RESULT_FILE_PATH) \n",
    "\n",
    "start = datetime.now(timezone('Asia/Seoul'))\n",
    "print(f\"Train start : {start}\")\n",
    "\n",
    "if MODEL_NAME == 'TripletNet':\n",
    "    if PRETRAINED_CHECKPOINT_PATH:\n",
    "        print(f\"Pretrained checkpoint found: {PRETRAINED_CHECKPOINT_PATH}\")\n",
    "    else:\n",
    "        print(\"No pretrained checkpoint found\")\n",
    "    model = TripletNet_model(IMAGE_SIZE, PRETRAINED_CHECKPOINT_PATH).configure_model()\n",
    "    model.summary()\n",
    "    model.add_loss(triplet_loss(model.outputs[0], model.outputs[1], model.outputs[2]))\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE))\n",
    "    history = model.fit(\n",
    "        train_triplet_generator,\n",
    "        steps_per_epoch=len(train_triplet_generator),\n",
    "        validation_data=val_triplet_generator,\n",
    "        validation_steps=len(val_triplet_generator),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "elif MODEL_NAME == 'EfficientNetB7':\n",
    "    model = EfficientNetB7_model(IMAGE_SIZE).configure_model()\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "end = datetime.now(timezone('Asia/Seoul'))\n",
    "print(f\"Train end : {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
